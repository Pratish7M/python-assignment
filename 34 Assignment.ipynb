{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. What is the Filter method in feature selection, and how does it work?\n",
    "Q2. How does the Wrapper method differ from the Filter method in feature selection?\n",
    "Q3. What are some common techniques used in Embedded feature selection methods?\n",
    "Q4. What are some drawbacks of using the Filter method for feature selection?\n",
    "Q5. In which situations would you prefer using the Filter method over the Wrapper method for feature\n",
    "selection?\n",
    "Q6. In a telecom company, you are working on a project to develop a predictive model for customer churn.\n",
    "You are unsure of which features to include in the model because the dataset contains several different\n",
    "ones. Describe how you would choose the most pertinent attributes for the model using the Filter Method.\n",
    "Q7. You are working on a project to predict the outcome of a soccer match. You have a large dataset with\n",
    "many features, including player statistics and team rankings. Explain how you would use the Embedded\n",
    "method to select the most relevant features for the model.\n",
    "Q8. You are working on a project to predict the price of a house based on its features, such as size, location,\n",
    "and age. You have a limited number of features, and you want to ensure that you select the most important\n",
    "ones for the model. Explain how you would use the Wrapper method to select the best set of features for the\n",
    "predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# **Q1. What is the Filter method in feature selection, and how does it work?**\n",
    "\n",
    "# **Answer:**\n",
    "\n",
    "# The Filter method in feature selection selects features based on their statistical properties or scores, without involving any machine learning model. It evaluates the intrinsic properties of the features and ranks or selects them based on their relevance to the target variable.\n",
    "\n",
    "# **How it works:**\n",
    "\n",
    "# 1.  **Statistical Measures:** The filter method uses statistical measures to assess the relationship between each feature and the target variable. Common measures include correlation, chi-squared test, ANOVA, mutual information, and variance.\n",
    "# 2.  **Scoring and Ranking:** Each feature is assigned a score based on the chosen statistical measure. The features are then ranked according to their scores.\n",
    "# 3.  **Selection:** You then select the top-ranked features based on a predefined threshold or a specific number of features.\n",
    "\n",
    "# **Q2. How does the Wrapper method differ from the Filter method in feature selection?**\n",
    "\n",
    "# **Answer:**\n",
    "\n",
    "# * **Filter Methods:**\n",
    "#     * Evaluate features independently of any specific machine learning model.\n",
    "#     * Use statistical measures to assess feature relevance.\n",
    "#     * Computationally efficient.\n",
    "#     * May overlook feature dependencies.\n",
    "# * **Wrapper Methods:**\n",
    "#     * Evaluate feature subsets by training and testing a specific machine learning model.\n",
    "#     * Search for the optimal feature subset that yields the best model performance.\n",
    "#     * Computationally expensive.\n",
    "#     * Can achieve better model performance by accounting for feature interactions.\n",
    "\n",
    "# **Q3. What are some common techniques used in Embedded feature selection methods?**\n",
    "\n",
    "# **Answer:**\n",
    "\n",
    "# Embedded feature selection methods perform feature selection as part of the model training process. Common techniques include:\n",
    "\n",
    "# * **Lasso (L1 Regularization):** Adds a penalty term to the model's loss function, which encourages some coefficients to become zero, effectively selecting a subset of features.\n",
    "# * **Ridge (L2 Regularization):** Similar to Lasso, but it shrinks coefficients towards zero without necessarily setting them to zero.\n",
    "# * **Tree-based methods (e.g., Random Forest, Gradient Boosting):** These models provide feature importance scores, which can be used to select the most relevant features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''**Q4. What are some drawbacks of using the Filter method for feature selection?**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "* **Ignores feature dependencies:** Filter methods often evaluate features independently, which can lead to the selection of redundant features.\n",
    "* **May not optimize for model performance:** Filter methods select features based on statistical measures, which may not directly correlate with model performance.\n",
    "* **Choice of statistical measure:** The choice of statistical measure can significantly impact the results, and there is no one-size-fits-all approach.\n",
    "\n",
    "**Q5. In which situations would you prefer using the Filter method over the Wrapper method for feature selection?**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "* **High-dimensional datasets:** Filter methods are computationally efficient and suitable for datasets with a large number of features.\n",
    "* **Preliminary feature selection:** Filter methods can be used as a quick and easy way to reduce the number of features before applying more computationally expensive wrapper methods.\n",
    "* **When model performance is not the primary concern:** If computational efficiency is more important than optimal model performance, filter methods can be a good choice.\n",
    "\n",
    "**Q6. In a telecom company, you are working on a project to develop a predictive model for customer churn. You are unsure of which features to include in the model because the dataset contains several different ones. Describe how you would choose the most pertinent attributes for the model using the Filter Method.**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "1.  **Data Preparation:** Load and preprocess the telecom customer churn dataset.\n",
    "2.  **Feature Selection:**\n",
    "    * If the target variable (churn) is categorical, use chi-squared test (`chi2`) for categorical features and mutual information (`mutual_info_classif`) for numerical features.\n",
    "    * If the target variable is numerical, use f_regression or mutual_info_regression.\n",
    "    * Use `SelectKBest` to select the top-k features based on the chosen statistical measure.\n",
    "3.  **Model Training:** Train the predictive model using the selected features.\n",
    "\n",
    "```python\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "\n",
    "#Example data.\n",
    "data = pd.DataFrame({'feature1':[1,2,3,4,5],'feature2':['a','b','a','c','b'],'feature3':[5,4,3,2,1],'churn':[1,0,1,0,1]})\n",
    "numerical_features = ['feature1','feature3']\n",
    "categorical_features = ['feature2']\n",
    "target = 'churn'\n",
    "\n",
    "#numerical feature selection\n",
    "selector_numerical = SelectKBest(mutual_info_classif, k=1)\n",
    "selector_numerical.fit(data[numerical_features],data[target])\n",
    "selected_numerical = numerical_features[selector_numerical.get_support()[0]]\n",
    "\n",
    "#categorical feature selection\n",
    "selector_categorical = SelectKBest(chi2, k=1)\n",
    "selector_categorical.fit(pd.get_dummies(data[categorical_features]),data[target])\n",
    "selected_categorical = categorical_features[selector_categorical.get_support()[0]]\n",
    "\n",
    "print(f\"selected numerical feature: {selected_numerical}\")\n",
    "print(f\"selected categorical feature: {selected_categorical}\")\n",
    "Q7. You are working on a project to predict the outcome of a soccer match. You have a large dataset with many features, including player statistics and team rankings. Explain how you would use the Embedded method to select the most relevant features for the model. Â  \n",
    "\n",
    "Answer:\n",
    "\n",
    "Data Preparation: Load and preprocess the soccer match dataset.\n",
    "Feature Selection:\n",
    "Use Lasso (L1 regularization) or Ridge (L2 regularization) with a linear regression model.\n",
    "Train the model and analyze the feature coefficients. Features with non-zero coefficients (Lasso) or large coefficients (Ridge) are considered important.\n",
    "Alternatively, use tree based methods like Random forest or gradient boosting and use feature importances from those models.\n",
    "Model Training: Train the predictive model using the selected features. ''''''"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
