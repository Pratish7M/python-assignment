{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "# Data Preprocessing and PCA Analysis\n",
    "\n",
    "## Q1: Min-Max Scaling\n",
    "Min-Max Scaling transforms data to a specific range, typically [0,1] or [-1,1]. It is defined as:\n",
    "$$ X' = \\frac{X - X_{min}}{X_{max} - X_{min}} \\times (new_{max} - new_{min}) + new_{min} $$\n",
    "\n",
    "### Example:\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Sample data\n",
    "data = np.array([1, 5, 10, 15, 20]).reshape(-1, 1)\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "print(\"Min-Max Scaled Data:\", scaled_data.flatten())\n",
    "\n",
    "\"\"\"\n",
    "## Q2: Unit Vector Scaling\n",
    "Also known as normalization, this technique scales each feature vector to have a unit norm.\n",
    "It differs from Min-Max scaling as it transforms values based on their magnitude rather than range.\n",
    "\n",
    "### Example:\n",
    "\"\"\"\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "normalizer = Normalizer()\n",
    "normalized_data = normalizer.fit_transform(data.reshape(1, -1))\n",
    "print(\"Unit Vector Normalized Data:\", normalized_data.flatten())\n",
    "\n",
    "\"\"\"\n",
    "## Q3: Principal Component Analysis (PCA)\n",
    "PCA is a dimensionality reduction technique that transforms data into principal components.\n",
    "\n",
    "### Example:\n",
    "\"\"\"\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample dataset (3 features)\n",
    "data = np.array([[2.5, 2.4], [0.5, 0.7], [2.2, 2.9], [1.9, 2.2], [3.1, 3.0], [2.3, 2.7], [2, 1.6], [1, 1.1], [1.5, 1.6], [1.1, 0.9]])\n",
    "\n",
    "pca = PCA(n_components=1)\n",
    "transformed_data = pca.fit_transform(data)\n",
    "print(\"Transformed Data:\", transformed_data.flatten())\n",
    "\n",
    "# Explained variance ratio\n",
    "print(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)\n",
    "\n",
    "plt.scatter(data[:,0], data[:,1], label='Original Data')\n",
    "plt.scatter(transformed_data, np.zeros_like(transformed_data), label='PCA Projection', color='r')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "## Q4: PCA and Feature Extraction\n",
    "PCA is used to extract the most important features by reducing dimensions while preserving variance.\n",
    "\n",
    "### Example:\n",
    "We can extract the most relevant components using PCA and select features contributing the most variance.\n",
    "\"\"\"\n",
    "pca = PCA(n_components=1)\n",
    "pca.fit(data)\n",
    "print(\"Principal Component:\", pca.components_)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "## Q5: Min-Max Scaling in Food Recommendation System\n",
    "\n",
    "We apply Min-Max scaling to normalize price, rating, and delivery time to bring them within a range (0,1).\n",
    "\"\"\"\n",
    "data = np.array([[10, 4.5, 30], [20, 3.8, 45], [15, 4.2, 35]])\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "print(\"Scaled Data:\", scaled_data)\n",
    "\n",
    "\"\"\"\n",
    "## Q6: PCA in Stock Price Prediction\n",
    "Reducing the dimensionality of stock market data by selecting principal components.\n",
    "\"\"\"\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(data)\n",
    "print(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "## Q7: Min-Max Scaling of Given Dataset\n",
    "Scaling dataset [1, 5, 10, 15, 20] to range [-1, 1].\n",
    "\"\"\"\n",
    "scaled_data = scaler.fit_transform(np.array([1, 5, 10, 15, 20]).reshape(-1, 1))\n",
    "print(\"Scaled Data:\", scaled_data.flatten())\n",
    "\n",
    "\"\"\"\n",
    "## Q8: PCA Feature Extraction for Medical Data\n",
    "Choosing the number of principal components based on explained variance.\n",
    "\"\"\"\n",
    "data = np.random.rand(100, 5)  # Simulated dataset with 5 features\n",
    "pca = PCA()\n",
    "pca.fit(data)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "num_components = np.argmax(cumulative_variance >= 0.95) + 1\n",
    "print(\"Number of Components to Retain:\", num_components)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
